{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc277e6-3209-450e-a252-cbb4497ace3d",
   "metadata": {},
   "source": [
    "# Practice training a deep neural network on the CIFAR10 image dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d47620a-0385-41e6-b162-0383272d27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "431cf4c9-9241-41ba-a454-949ea0dccc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f18e04-c354-4f33-b033-bc881d12ded3",
   "metadata": {},
   "source": [
    "a. Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the Swish activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4da565-5587-4985-9252-9eee1e7a93c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    ")\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Split training data into train and validation subsets (e.g., 80%/20%)\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0f16c0d1-0e05-4abc-8ecc-4fb9cb7a5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(layer, nonlinearity='leaky_relu'):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity=nonlinearity)\n",
    "        torch.nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1dff4f1-09d1-4588-9f07-d581d1803271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10(nn.Module):\n",
    "    def __init__(self, input_features=3*32*32, output_neurons=100, num_classes=10, hidden_layers=20):\n",
    "        super(CIFAR10, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layer_first = nn.Linear(input_features, output_neurons)\n",
    "        layers.append(layer_first)\n",
    "        layers.append(Swish())\n",
    "        \n",
    "        for i in range(hidden_layers-1):\n",
    "            layer = nn.Linear(output_neurons, output_neurons)\n",
    "            layers.append(layer)\n",
    "            layers.append(Swish())\n",
    "\n",
    "        layer_last = nn.Linear(output_neurons, num_classes)\n",
    "        layers.append(layer_last)\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.net.apply(weights_init)\n",
    "\n",
    "    def forward(self, X):\n",
    "        flatten = nn.Flatten()\n",
    "        X = flatten(X)\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65dabd5-eeaf-4274-bda5-fc2c25027abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, device, epochs=50, patience=5, standardization=None, standardize=False):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        per_epoch_train_loss = 0.0\n",
    "        time_per_epoch = time.time()\n",
    "        for data in train_loader:\n",
    "            inputs, targets = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if standardize:\n",
    "                inputs = standardization(inputs)\n",
    "                \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            per_epoch_train_loss += loss.item()\n",
    "\n",
    "        avg_per_epoch_train_loss = per_epoch_train_loss / len(train_loader)\n",
    "        writer.add_scalar(\"Loss/Train\", avg_per_epoch_train_loss, epoch+1)\n",
    "\n",
    "        per_epoch_val_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for data in val_loader:\n",
    "            inputs, targets = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                loss = criterion(outputs, targets)                \n",
    "                per_epoch_val_loss += loss.item()\n",
    "                \n",
    "        avg_per_epoch_val_loss = per_epoch_val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        writer.add_scalar(\"Loss/Val\", avg_per_epoch_val_loss, epoch+1)\n",
    "        writer.add_scalar(\"Accuracy/Val\", val_accuracy, epoch+1)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_per_epoch_train_loss:.4f}, \" \n",
    "              f\"Val Loss: {avg_per_epoch_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, Time Elapsed {time.time() - time_per_epoch:.3f}s\")\n",
    "\n",
    "        if  avg_per_epoch_val_loss < best_val_loss:\n",
    "            patience_counter = 0\n",
    "            best_val_loss = avg_per_epoch_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"\\nTotal Time for Training {(end-start)/60:.3f}m\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40e81b0-3d08-4dea-aee2-69216b18ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, test_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs  = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "aa2f9902-974d-4fd6-b6c7-7cc1e4354622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: 1.9001, Val Loss: 1.7899, Val Acc: 33.84%, Time Elapsed 56.610s\n",
      "Epoch [2/5], Train Loss: 1.6878, Val Loss: 1.6607, Val Acc: 40.21%, Time Elapsed 57.438s\n",
      "Epoch [3/5], Train Loss: 1.5644, Val Loss: 1.5988, Val Acc: 41.87%, Time Elapsed 50.313s\n",
      "Epoch [4/5], Train Loss: 1.4805, Val Loss: 1.5559, Val Acc: 45.23%, Time Elapsed 54.452s\n",
      "Epoch [5/5], Train Loss: 1.4158, Val Loss: 1.5333, Val Acc: 45.58%, Time Elapsed 51.567s\n",
      "\n",
      "Total Time for Training 4.506m\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter()\n",
    "\n",
    "cifar10  = CIFAR10()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(cifar10.parameters(), lr=0.001)\n",
    "model = train(cifar10, train_loader, val_loader, criterion, optimizer, device=device, epochs=5)\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "76d1c3b6-4aa1-40a4-8b61-546071cf4c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 48.54%\n"
     ]
    }
   ],
   "source": [
    "eval(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6b92185-8faf-41a1-90cd-4e294ebe91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10V2(nn.Module):\n",
    "    def __init__(self, input_features=3*32*32, output_neurons=100, num_classes=10, hidden_layers=20):\n",
    "        super(CIFAR10V2, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layer_first = nn.Linear(input_features, output_neurons)\n",
    "        layers.append(layer_first)\n",
    "        layers.append(nn.BatchNorm1d(output_neurons))\n",
    "        layers.append(Swish())\n",
    "        \n",
    "        for i in range(hidden_layers-1):\n",
    "            layer = nn.Linear(output_neurons, output_neurons)\n",
    "            layers.append(layer)\n",
    "            layers.append(nn.BatchNorm1d(output_neurons))\n",
    "            layers.append(Swish())\n",
    "\n",
    "        layer_last = nn.Linear(output_neurons, num_classes)\n",
    "        layers.append(layer_last)\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.net.apply(weights_init)\n",
    "\n",
    "    def forward(self, X):\n",
    "        flatten = nn.Flatten()\n",
    "        X = flatten(X)\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "949d346c-c56a-439a-82e7-edda2468d878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: 2.0241, Val Loss: 1.8095, Val Acc: 33.79%, Time Elapsed 61.484s\n",
      "Epoch [2/5], Train Loss: 1.7113, Val Loss: 1.6768, Val Acc: 40.24%, Time Elapsed 61.726s\n",
      "Epoch [3/5], Train Loss: 1.6001, Val Loss: 1.6090, Val Acc: 43.22%, Time Elapsed 60.703s\n",
      "Epoch [4/5], Train Loss: 1.5270, Val Loss: 1.5700, Val Acc: 44.20%, Time Elapsed 62.025s\n",
      "Epoch [5/5], Train Loss: 1.4740, Val Loss: 1.5388, Val Acc: 45.88%, Time Elapsed 61.364s\n",
      "\n",
      "Total Time for Training 5.122m\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter()\n",
    "\n",
    "cifar10v2  = CIFAR10V2()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(cifar10v2.parameters(), lr=0.001)\n",
    "model = train(cifar10v2, train_loader, val_loader, criterion, optimizer, device=device, epochs=5)\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc4c6e0-a5f4-4e10-85d0-b35c0a0beddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_lecun(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        gain = np.sqrt(sum(layer.weight.shape) / layer.weight.shape[1])\n",
    "        torch.nn.init.xavier_normal_(layer.weight, gain=gain)\n",
    "        torch.nn.init.constant_(layer.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9c815396-c5d2-452f-bb9b-4562d1926e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10V3(nn.Module):\n",
    "    def __init__(self, input_features=3*32*32, output_neurons=100, num_classes=10, hidden_layers=20):\n",
    "        super(CIFAR10V3, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layer_first = nn.Linear(input_features, output_neurons)\n",
    "        layers.append(layer_first)\n",
    "        layers.append(nn.SELU())\n",
    "        \n",
    "        for i in range(hidden_layers-1):\n",
    "            layer = nn.Linear(output_neurons, output_neurons)\n",
    "            layers.append(layer)\n",
    "            layers.append(nn.SELU())\n",
    "\n",
    "        layer_last = nn.Linear(output_neurons, num_classes)\n",
    "        layers.append(layer_last)\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.net.apply(weights_init_lecun)\n",
    "\n",
    "    def forward(self, X):\n",
    "        flatten = nn.Flatten()\n",
    "        X = flatten(X)\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d78e1371-2be1-4646-802f-a5fc8c9cdf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: 2.1656, Val Loss: 2.0423, Val Acc: 28.54%, Time Elapsed 22.917s\n",
      "Epoch [2/5], Train Loss: 1.7683, Val Loss: 2.1380, Val Acc: 30.68%, Time Elapsed 23.921s\n",
      "Epoch [3/5], Train Loss: 1.6571, Val Loss: 1.7635, Val Acc: 39.64%, Time Elapsed 26.930s\n",
      "Epoch [4/5], Train Loss: 1.5897, Val Loss: 2.0045, Val Acc: 32.44%, Time Elapsed 52.490s\n",
      "Epoch [5/5], Train Loss: 1.5328, Val Loss: 1.7638, Val Acc: 39.46%, Time Elapsed 52.903s\n",
      "\n",
      "Total Time for Training 2.988m\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter()\n",
    "standardize = transforms.Compose(\n",
    "     [transforms.Normalize((0, 0, 0), (1, 1, 1))]\n",
    ")\n",
    "\n",
    "cifar10v3  = CIFAR10V3()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(cifar10v3.parameters(), lr=0.001)\n",
    "model = train(cifar10v3, train_loader, val_loader, criterion, optimizer, device=device, epochs=5)\n",
    "writer.flush()\n",
    "writer.close()\n",
    "eval(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c112e301-2678-4f1d-8ee2-8e45554efd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10V4(nn.Module):\n",
    "    def __init__(self, input_features=3*32*32, output_neurons=100, num_classes=10, hidden_layers=20):\n",
    "        super(CIFAR10V4, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layer_first = nn.Linear(input_features, output_neurons)\n",
    "        layers.append(layer_first)\n",
    "        layers.append(nn.SELU())\n",
    "        \n",
    "        for i in range(hidden_layers-1):\n",
    "            layer = nn.Linear(output_neurons, output_neurons)\n",
    "            layers.append(layer)\n",
    "            layers.append(nn.SELU())\n",
    "\n",
    "        layers.append(nn.AlphaDropout(p=0.1))\n",
    "        layer_last = nn.Linear(output_neurons, num_classes)\n",
    "        layers.append(layer_last)\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.net.apply(weights_init_lecun)\n",
    "\n",
    "    def forward(self, X):\n",
    "        flatten = nn.Flatten()\n",
    "        X = flatten(X)\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2e6fb0aa-8128-456f-af6b-f64a6e0d28cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: 2.1893, Val Loss: 2.3306, Val Acc: 24.92%, Time Elapsed 57.351s\n",
      "Epoch [2/5], Train Loss: 1.7998, Val Loss: 1.7783, Val Acc: 37.08%, Time Elapsed 53.170s\n",
      "Epoch [3/5], Train Loss: 1.7017, Val Loss: 1.7400, Val Acc: 40.48%, Time Elapsed 51.750s\n",
      "Epoch [4/5], Train Loss: 1.6410, Val Loss: 1.8284, Val Acc: 36.38%, Time Elapsed 53.184s\n",
      "Epoch [5/5], Train Loss: 1.5821, Val Loss: 1.9535, Val Acc: 34.10%, Time Elapsed 54.880s\n",
      "\n",
      "Total Time for Training 4.508m\n",
      "Test Accuracy: 34.48%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter()\n",
    "\n",
    "cifar10v4  = CIFAR10V4()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(cifar10v4.parameters(), lr=0.001)\n",
    "model = train(cifar10v4, train_loader, val_loader, criterion, optimizer, device=device, epochs=5)\n",
    "writer.flush()\n",
    "writer.close()\n",
    "eval(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f4b2f129-2f3c-4432-9fce-9f7c2e1e4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10v4  = CIFAR10V4()\n",
    "cifar10v4 = cifar10v4.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f11f0ccb-7980-4680-99cb-99f6c443f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(nn.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs).train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "896ed043-5dca-4879-be9f-930d8f924608",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = nn.Sequential(*[\n",
    "    MCAlphaDropout(layer.p)\n",
    "    if isinstance(layer, nn.AlphaDropout)\n",
    "    else layer\n",
    "    for layer in cifar10v4.net\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f9266608-6d82-4de6-8e5f-e64041035818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor(t.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "1cf40633-4a19-49a6-99e3-0072213eefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p = torch.max(torch.tensor(y_scores), 1)\n",
    "p = p.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "598693de-a812-4c7b-9753-5ef64063f472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 32])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = targets.size(0)\n",
    "correct += (predicted == targets).sum().item()\n",
    "        \n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "dafa52f9-25f5-4896-8f7c-365fa4c9fc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2214, -9.3684,  7.8547, -6.9430, -3.6141,  1.9189,  0.3642,  4.5611,\n",
       "         -4.2872,  0.9910]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "X = flatten(inp)\n",
    "mc_model(X[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a06e0b48-0de4-4ac9-b6e8-d9b5e15948e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predictions(model, test_loader, device='cpu'):\n",
    "    model.train(True)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_probas = []\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs  = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.detach().numpy()\n",
    "            y_probas.append(outputs)\n",
    "            \n",
    "    return np.vstack(y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "db280cbd-29ba-49bc-933a-03bf34ee5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.vstack([targets.view(-1, 1) for _, targets in test_loader])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d6dacf30-1375-4eb2-857b-d5c9f6f44043",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([mc_dropout_predictions(cifar10v4, test_loader) for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "922265a9-4346-457b-a7cf-6e5b95bbff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f5dab1bf-b9aa-4df7-a608-24f6bfbcce54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2cf8772b-b35a-4d91-88c2-df48c56c3b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  2., 12., -2., -5., 10., 12., -7., -2., 13.]],\n",
       "       grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10v4.train(False)\n",
    "cifar10v4(inp[:1]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a83ee331-06ef-40c5-8329-01edf5eb53b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20852), started 2 days, 14:03:45 ago. (Use '!kill 20852' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-63e9976a79f83c1f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-63e9976a79f83c1f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a4903-62a6-45bc-b98c-2dbe456eedb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
