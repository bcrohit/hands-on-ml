{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc277e6-3209-450e-a252-cbb4497ace3d",
   "metadata": {},
   "source": [
    "# Practice training a deep neural network on the CIFAR10 image dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47620a-0385-41e6-b162-0383272d27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "431cf4c9-9241-41ba-a454-949ea0dccc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f18e04-c354-4f33-b033-bc881d12ded3",
   "metadata": {},
   "source": [
    "a. Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the Swish activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1e4da565-5587-4985-9252-9eee1e7a93c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Split training data into train and validation subsets (e.g., 80%/20%)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0f16c0d1-0e05-4abc-8ecc-4fb9cb7a5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        torch.nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b1dff4f1-09d1-4588-9f07-d581d1803271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10(nn.Module):\n",
    "    def __init__(self, input_features=3*32*32, output_neurons=100, num_classes=10, hidden_layers=20):\n",
    "        super(CIFAR10, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layer_first = nn.Linear(input_features, output_neurons)\n",
    "        layers.append(layer_first)\n",
    "        layers.append(Swish())\n",
    "        \n",
    "        for i in range(hidden_layers-1):\n",
    "            layer = nn.Linear(output_neurons, output_neurons)\n",
    "            layers.append(layer)\n",
    "            layers.append(Swish())\n",
    "\n",
    "        layer_last = nn.Linear(output_neurons, num_classes)\n",
    "        layers.append(layer_last)\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.net.apply(weights_init)\n",
    "\n",
    "    def forward(self, X):\n",
    "        flatten = nn.Flatten()\n",
    "        X = flatten(X)\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "c65dabd5-eeaf-4274-bda5-fc2c25027abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, device, epochs=50, patience=5):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        per_epoch_train_loss = 0.0\n",
    "        time_per_epoch = time.time()\n",
    "        for data in train_loader:\n",
    "            inputs, targets = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            per_epoch_train_loss += loss.item()\n",
    "\n",
    "        avg_per_epoch_train_loss = per_epoch_train_loss / len(train_loader)\n",
    "        writer.add_scalar(\"Loss/Train\", avg_per_epoch_train_loss, epoch+1)\n",
    "\n",
    "        per_epoch_val_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for data in val_loader:\n",
    "            inputs, targets = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                loss = criterion(outputs, targets)                \n",
    "                per_epoch_val_loss += loss.item()\n",
    "                \n",
    "        avg_per_epoch_val_loss = per_epoch_val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        writer.add_scalar(\"Loss/Val\", avg_per_epoch_val_loss, epoch+1)\n",
    "        writer.add_scalar(\"Accuracy/Val\", val_accuracy, epoch+1)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_per_epoch_train_loss:.4f}, \" \n",
    "              f\"Val Loss: {avg_per_epoch_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, Time Elapsed {time.time() - time_per_epoch:.3f}s\")\n",
    "\n",
    "        if  avg_per_epoch_val_loss < best_val_loss:\n",
    "            patience_counter = 0\n",
    "            best_val_loss = avg_per_epoch_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"\\nTotal Time for Training {(end-start)/60:.3f}m\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "c40e81b0-3d08-4dea-aee2-69216b18ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, test_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs  = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "aa2f9902-974d-4fd6-b6c7-7cc1e4354622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: 1.9001, Val Loss: 1.7899, Val Acc: 33.84%, Time Elapsed 56.610s\n",
      "Epoch [2/5], Train Loss: 1.6878, Val Loss: 1.6607, Val Acc: 40.21%, Time Elapsed 57.438s\n",
      "Epoch [3/5], Train Loss: 1.5644, Val Loss: 1.5988, Val Acc: 41.87%, Time Elapsed 50.313s\n",
      "Epoch [4/5], Train Loss: 1.4805, Val Loss: 1.5559, Val Acc: 45.23%, Time Elapsed 54.452s\n",
      "Epoch [5/5], Train Loss: 1.4158, Val Loss: 1.5333, Val Acc: 45.58%, Time Elapsed 51.567s\n",
      "\n",
      "Total Time for Training 4.506m\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter()\n",
    "\n",
    "cifar10  = CIFAR10()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(cifar10.parameters(), lr=0.001)\n",
    "model = train(cifar10, train_loader, val_loader, criterion, optimizer, device=device, epochs=5)\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "76d1c3b6-4aa1-40a4-8b61-546071cf4c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 46.46%\n"
     ]
    }
   ],
   "source": [
    "eval(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "bbd32dca-d879-46e2-b18d-7be527b4dba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "b6b92185-8faf-41a1-90cd-4e294ebe91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10V2(nn.Module):\n",
    "    def __init__(self, input_features=3*32*32, output_neurons=100, num_classes=10, hidden_layers=20):\n",
    "        super(CIFAR10V2, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layer_first = nn.Linear(input_features, output_neurons)\n",
    "        layers.append(layer_first)\n",
    "        layers.append(nn.BatchNorm1d(output_neurons))\n",
    "        layers.append(Swish())\n",
    "        \n",
    "        for i in range(hidden_layers-1):\n",
    "            layer = nn.Linear(output_neurons, output_neurons)\n",
    "            layers.append(layer)\n",
    "            layers.append(nn.BatchNorm1d(output_neurons))\n",
    "            layers.append(Swish())\n",
    "\n",
    "        layer_last = nn.Linear(output_neurons, num_classes)\n",
    "        layers.append(layer_last)\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.net.apply(weights_init)\n",
    "\n",
    "    def forward(self, X):\n",
    "        flatten = nn.Flatten()\n",
    "        X = flatten(X)\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d346c-c56a-439a-82e7-edda2468d878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: 2.0241, Val Loss: 1.8095, Val Acc: 33.79%, Time Elapsed 61.484s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter()\n",
    "\n",
    "cifar10v2  = CIFAR10V2()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(cifar10v2.parameters(), lr=0.001)\n",
    "model = train(cifar10v2, train_loader, val_loader, criterion, optimizer, device=device, epochs=5)\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "a83ee331-06ef-40c5-8329-01edf5eb53b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20852), started 0:20:23 ago. (Use '!kill 20852' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5ae70906ba3bc82a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5ae70906ba3bc82a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704215c-1ed3-4a00-b26c-cc6b41bf9b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
